{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2001 images belonging to 2 classes.\n",
      "Found 802 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.7200 - accuracy: 0.5204 - val_loss: 0.6167 - val_accuracy: 0.5825\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.6706 - accuracy: 0.5899 - val_loss: 0.6955 - val_accuracy: 0.6272\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.6424 - accuracy: 0.6312 - val_loss: 0.6582 - val_accuracy: 0.6908\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.6100 - accuracy: 0.6756 - val_loss: 0.4519 - val_accuracy: 0.6247\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.5923 - accuracy: 0.6997 - val_loss: 0.6146 - val_accuracy: 0.6934\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.5803 - accuracy: 0.6917 - val_loss: 0.6620 - val_accuracy: 0.7061\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.5622 - accuracy: 0.7078 - val_loss: 0.5224 - val_accuracy: 0.6730\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 14s 111ms/step - loss: 0.5573 - accuracy: 0.7370 - val_loss: 0.5061 - val_accuracy: 0.7201\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.5506 - accuracy: 0.7285 - val_loss: 0.4754 - val_accuracy: 0.7163\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5639 - accuracy: 0.7229 - val_loss: 0.5112 - val_accuracy: 0.7150\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.5205 - accuracy: 0.7411 - val_loss: 0.6244 - val_accuracy: 0.6489\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5163 - accuracy: 0.7592 - val_loss: 0.5494 - val_accuracy: 0.7341\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.5197 - accuracy: 0.7622 - val_loss: 0.6503 - val_accuracy: 0.7494\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.5099 - accuracy: 0.7557 - val_loss: 0.6177 - val_accuracy: 0.7099\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.4860 - accuracy: 0.7788 - val_loss: 0.6848 - val_accuracy: 0.7163\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.4843 - accuracy: 0.7763 - val_loss: 0.4647 - val_accuracy: 0.7481\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4901 - accuracy: 0.7733 - val_loss: 1.1055 - val_accuracy: 0.6679\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.4488 - accuracy: 0.8040 - val_loss: 0.6560 - val_accuracy: 0.7774\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4610 - accuracy: 0.7940 - val_loss: 0.8381 - val_accuracy: 0.6972\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.4553 - accuracy: 0.7920 - val_loss: 0.3940 - val_accuracy: 0.7710\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4202 - val_accuracy: 0.7595\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.4603 - accuracy: 0.7839 - val_loss: 0.7067 - val_accuracy: 0.7455\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.4346 - accuracy: 0.8111 - val_loss: 0.4175 - val_accuracy: 0.7532\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4381 - accuracy: 0.8175 - val_loss: 0.3708 - val_accuracy: 0.7252\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4246 - accuracy: 0.8227 - val_loss: 0.7034 - val_accuracy: 0.6781\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.4445 - accuracy: 0.8152 - val_loss: 0.4277 - val_accuracy: 0.7786\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.4141 - accuracy: 0.8215 - val_loss: 0.5978 - val_accuracy: 0.7226\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.4516 - accuracy: 0.8178 - val_loss: 0.5009 - val_accuracy: 0.7659\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.4240 - accuracy: 0.8071 - val_loss: 0.6219 - val_accuracy: 0.7684\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.4280 - accuracy: 0.8090 - val_loss: 0.2377 - val_accuracy: 0.7379\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.4355 - accuracy: 0.8102 - val_loss: 0.1956 - val_accuracy: 0.7277\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.4041 - accuracy: 0.8232 - val_loss: 0.3807 - val_accuracy: 0.7684\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.4286 - accuracy: 0.8045 - val_loss: 0.5276 - val_accuracy: 0.7659\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.4205 - accuracy: 0.8272 - val_loss: 0.4304 - val_accuracy: 0.7481\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.4172 - accuracy: 0.8205 - val_loss: 0.4126 - val_accuracy: 0.7176\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.4324 - accuracy: 0.8252 - val_loss: 0.3813 - val_accuracy: 0.7494\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.3988 - accuracy: 0.8274 - val_loss: 0.8891 - val_accuracy: 0.7875\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 14s 111ms/step - loss: 0.3907 - accuracy: 0.8317 - val_loss: 0.3596 - val_accuracy: 0.7455\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.4092 - accuracy: 0.8116 - val_loss: 0.4684 - val_accuracy: 0.7926\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.4185 - accuracy: 0.8245 - val_loss: 0.9319 - val_accuracy: 0.7634\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.4095 - accuracy: 0.8183 - val_loss: 0.5666 - val_accuracy: 0.7710\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.4005 - accuracy: 0.8257 - val_loss: 0.3619 - val_accuracy: 0.7774\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.4130 - accuracy: 0.8348 - val_loss: 0.6488 - val_accuracy: 0.7837\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.4104 - accuracy: 0.8315 - val_loss: 0.3709 - val_accuracy: 0.7723\n",
      "Epoch 45/50\n",
      "102/125 [=======================>......] - ETA: 2s - loss: 0.4281 - accuracy: 0.8227"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as B\n",
    "\n",
    "width, height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if B.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, width, img_height)\n",
    "else:\n",
    "    input_shape = (width, height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('train_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data_dir = 'data/images'\n",
    "test_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_val_generator = test_val_datagen.flow_from_directory(\n",
    "    image_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5793297]\n",
      " [0.4251811]]\n"
     ]
    }
   ],
   "source": [
    "print (model.predict(test_val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "result_t = []\n",
    "for k in range(51):\n",
    "    result_t.append(yhat[k])\n",
    "\n",
    "print(len(result_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = validation_generator\n",
    "y_pred = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got <keras.preprocessing.image.DirectoryIterator object at 0x0000020F08B1D3C8>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-cbbdb823927e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                        zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                          str(average_options))\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m     80\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[1;32m--> 241\u001b[1;33m                          'got %r' % y)\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0msparse_pandas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'SparseSeries'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SparseArray'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got <keras.preprocessing.image.DirectoryIterator object at 0x0000020F08B1D3C8>"
     ]
    }
   ],
   "source": [
    " f1_score(y_true, result_t, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
